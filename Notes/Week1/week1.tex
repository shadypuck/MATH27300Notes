\documentclass[../notes.tex]{subfiles}

\pagestyle{main}
\renewcommand{\chaptermark}[1]{\markboth{\chaptername\ \thechapter\ (#1)}{}}

\begin{document}




\chapter{Introduction to ODEs}
\section{Definitions and Scope}
\begin{itemize}
    \item \marginnote{9/28:}Questions:
    \begin{itemize}
        \item When will the PDFs be made available?
    \end{itemize}
    \item Office: Eckhart 309.
    \begin{itemize}
        \item Office hours: MWF 3:00-4:00.
    \end{itemize}
    \item Reader: Walker Lewis. His contact info is in the syllabus.
    \item Final grade is based on\dots
    \begin{itemize}
        \item 2 midterms (15 pts. each; weeks 4 and 8).
        \item Final exam (35 pts.).
        \item HW (35 pts.).
        \item Bonus problems (15 pts).
    \end{itemize}
    \item Total points for the quarter is 115. The bonus problems usually arise from advanced math and incorporate more advanced knowledge, and we are encouraged to seek out all relevant resources as long as we write up our own solutions.
    \item \textbf{Ordinary differential equation}: An equation that involves an unknown function of a single variable; an equation that takes the form $F(t,y,y',\dots,y^{(n)})=0$. \emph{Also known as} \textbf{ODE}.
    \begin{itemize}
        \item $F$ is a known function.
        \item $t$ is an argument (time). $x$ is also used (when space is involved).
        \item $y=y(t)$ is an unknown function.
    \end{itemize}
    \item \textbf{Order $\bm{n}$} (ODE): An ODE for which the $n^\text{th}$ derivative of $y$ is the highest-order derivative involved (and is involved).
    \item ODEs are of the form $y'=f(t,y)$ or, more generally, $y^{(n)}=F(t,y,y',\dots,y^{(n-1)})$.
    \begin{itemize}
        \item We can transform this second form into the first form via
        \begin{align*}
            Y &=
            \begin{pmatrix}
                y\\
                y'\\
                \vdots\\
                y^{(n-1)}\\
            \end{pmatrix}&
            f(t,y) &=
            \begin{pmatrix}
                Y^2\\
                Y^3\\
                \vdots\\
                F(t,Y^1,Y^2,\dots,Y^{n-1})\\
            \end{pmatrix}
        \end{align*}
        This makes $Y'=f(t,Y)$ equal to the system of equations
        \begin{align*}
            (Y^1)' &= Y^2\\
            (Y^2)' &= Y^3\\
            &\vdots\\
            (Y^{n-1})' &= F(t,Y^1,Y^2,\dots,Y^{n-1})
        \end{align*}
        \begin{itemize}
            \item Think about this conversion more.
        \end{itemize}
        \item Thus, we mainly focus on equations of the form $y'=f(t,y)$ (where $y$ may be a scalar or vector function), because that's general enough.
    \end{itemize}
    \item \textbf{Linear} (ODE): Any ODE that can be written in the form
    \begin{equation*}
        y' = A(t)y+f(t)
    \end{equation*}
    \item Because of the above, this naturally includes equations of the form
    \begin{equation*}
        y^{(n)}+a_{n-1}(t)y^{(n-1)}+\cdots+a_0(t)y = b(t)
    \end{equation*}
    \begin{itemize}
        \item Indeed, if we define $Y=(y,y',\dots,y^{(n-1)})$, then we may express this equation in the form
        \begin{align*}
            \underbrace{
                \begin{pmatrix}
                    Y^1\\
                    Y^2\\
                    \vdots\\
                    Y^n\\
                \end{pmatrix}'
            }_{Y'}
            &= \underbrace{
                \begin{pmatrix}
                    Y^2\\
                    Y^3\\
                    \vdots\\
                    b(t)-a_0(t)Y^1-\cdots-a_{n-1}(t)Y^{n-1}\\
                \end{pmatrix}
            }_{g(t,y)}\\
            &=
            \begin{pmatrix}
                Y^2\\
                Y^3\\
                \vdots\\
                -a_0(t)Y^1-\cdots-a_{n-1}(t)Y^{n-1}\\
            \end{pmatrix}
            +\underbrace{
                \begin{pmatrix}
                    0\\
                    0\\
                    \vdots\\
                    b(t)\\
                \end{pmatrix}
            }_{f(t)}\\
            &= \underbrace{
                \begin{pmatrix}
                    0 & 1 & 0 & \cdots & 0\\
                    0 & 0 & 1 & \cdots & 0\\
                    \vdots & \vdots & \vdots & \ddots & \vdots\\
                    0 & 0 & 0 & \cdots & 1\\
                    -a_0(t) & -a_1(t) & -a_2(t) & \cdots & -a_{n-1}(t)\\
                \end{pmatrix}
            }_{A(t)}\underbrace{
                \vphantom{
                    \begin{pmatrix}
                        0 & 1 & 0 & \cdots & 0\\
                        0 & 0 & 1 & \cdots & 0\\
                        \vdots & \vdots & \vdots & \ddots & \vdots\\
                        0 & 0 & 0 & \cdots & 1\\
                        -a_0(t) & -a_1(t) & -a_2(t) & \cdots & -a_{n-1}(t)\\
                    \end{pmatrix}
                }
                \begin{pmatrix}
                    Y^1\\
                    Y^2\\
                    \vdots\\
                    Y^n\\
                \end{pmatrix}
            }_Y+\underbrace{
                \vphantom{
                    \begin{pmatrix}
                        0 & 1 & 0 & \cdots & 0\\
                        0 & 0 & 1 & \cdots & 0\\
                        \vdots & \vdots & \vdots & \ddots & \vdots\\
                        0 & 0 & 0 & \cdots & 1\\
                        -a_0(t) & -a_1(t) & -a_2(t) & \cdots & -a_{n-1}(t)\\
                    \end{pmatrix}
                }
                \begin{pmatrix}
                    0\\
                    0\\
                    \vdots\\
                    b(t)\\
                \end{pmatrix}
            }_{f(t)}
        \end{align*}
        \item This conversion and its implications is covered in more depth in Lecture 4.1.
    \end{itemize}
    \item \textbf{Nonlinear} (ODE): An ODE that is not linear.
    \item \textbf{Autonomous} (ODE): An ODE that can be written in the form
    \begin{equation*}
        y' = f(y)
    \end{equation*}
    \begin{itemize}
        \item Remember that $y$ can be a scalar or a vector function.
        \item Solutions to autonomous ODEs can start at \emph{any} time $t$ and still be valid.
        \begin{itemize}
            \item For example, take the scalar ODE $y'=y$. It's general solution is $y(t)=a\e[t-t_0]$ for some $a\in\R$ and $t_0$ being the start time. Importantly, notice that we can make $t_0$ take any value we want and $y(t)$ will still solve $y'=y$.
        \end{itemize}
    \end{itemize}
    \item \textbf{Nonautonomous} (ODE): An ODE that is not autonomous.
    \begin{itemize}
        \item We will not investigate these in this course.
    \end{itemize}
    \item \textbf{Initial value problem}: A problem of the form, "find $y(t)$ such that the following holds."
    \begin{equation*}
        \begin{cases}
            y' = f(t,y)\\
            y(t_0) = y_0
        \end{cases}
    \end{equation*}
    \emph{Also known as} \textbf{IVP}, \textbf{Cauchy problem}.
    \item Locally well-posed (LWP) conditions:
    \begin{enumerate}
        \item Existence (local in time).
        \item Uniqueness (you cannot have multiple solutions).
        \item Local stability (if you perturb your initial value or equation a little bit, you do not expect your solution to vary crazily [esp. locally]).
    \end{enumerate}
    \item Example of a nonunique ODE:
    \begin{itemize}
        \item $y'=\sqrt{y}$, $y(0)=0$ has solutions $y_1(t)=0$ ($t\geq 0$) and $y_2(t)=t^2/4$ ($t\geq 0$).
        \item We will investigate the reason later.
    \end{itemize}
    \item Preview of the reason: \textbf{Cauchy-Lipschitz Theorem} or \textbf{Picard-Lindel\"{o}f Theorem}.
    \begin{itemize}
        \item As long as the ODE is \textbf{Lipschitz continuous}, it's locally stable.
    \end{itemize}
    \item \textbf{Lipschitz continuous} (function): A function $f$ such that
    \begin{equation*}
        |f(t,y_1)-f(t,y_2)| \leq L|y_1-y_2|
    \end{equation*}
    \begin{itemize}
        \item But in the counterexample above, the slope of the chord from 0 to $y(t)$ approaches infinity as $t\to 0$.
    \end{itemize}
    \item \textbf{Peano Existence Theorem}: Under certain conditions, there exists a solution to a given IVP.
    \item \textbf{Dynamical system}: A law under which a particle evolves over time. $y'=f(t,y)$, IVP is LWP.
    \item If the IVP $y'=f(t,y)$, $y(t_0)=y_0$ is locally well-posed, then the map $\Phi(t,x)$ which solves
    \begin{equation*}
        \begin{cases}
            \dv{t}\Phi(t,x) = f(t,\Phi(t,x))\\
            \Phi(0,x) = x
        \end{cases}
    \end{equation*}
    is well-defined and satisfies the property
    \begin{equation*}
        \Phi(t_2,\Phi(t_1,x)) = \Phi(t_1+t_2,x)
    \end{equation*}
    \begin{itemize}
        \item $\Phi$ is very related to $y$, though how exactly is still a bit of a mystery?? Perhaps it's
        \begin{equation*}
            \Phi(t,x) = y(t)
        \end{equation*}
        where $y$ is the solution to the IVP $y'=f(t,y)$, $y(0)=x$.
        \item It appears that $\Phi(t,x)$ is related to $f_t(x)$ from \textcite{bib:DifferentialForms}, i.e., we are picking a point $x$ and traveling along its integral curve for time $t$.
        \item Think about $y(t)=a\e[t-t_0]$ as an integral curve of the one-dimensional vector field $X(x)=x$.
        \item The final property appears to express the notion that if you have a system and evolve it by time $t_1$ and then time $t_2$, that's equivalent to evolving it by time $t_1+t_2$.
    \end{itemize}
    \item \textbf{Steady flow}: A vector field on a manifold contained in $\R^2$ or $\R^3$ that does not vary with time.
    \item Let $X$ be a vector field.
    \begin{itemize}
        \item Trajectory of a particle: At $x\in\Omega$, the velocity of the particle should coincide with $X(x)$.
        \item The differential equation $\dot{x}=X(x)$ is what we're interested in.
        \item A solid shape gets shifted and deformed (imagine a chunk of water falling out of the end of a pipe). This is the \textbf{local group of transformation}.
        \item Differential geometry is the purview of such things.
    \end{itemize}
    \item Newton's law of motion $F=m\cdot a$ applied to $n$ particles is nothing but the system of equations
    \begin{equation*}
        m_ix_i'' = F_i(x_1,\dots,x_n)
    \end{equation*}
    for $i=1,\dots,n$.
    \begin{itemize}
        \item Many well-known examples.
        \item The best known one perhaps is that of uniform acceleration of a single particle. In this case,
        \begin{equation*}
            m_0x'' = f_0
        \end{equation*}
        \begin{itemize}
            \item The solution is
            \begin{equation*}
                x(t) = \frac{f_0}{2m_0}t^2+v_0t+x_0
            \end{equation*}
            where $x_0=x(0)$ and $v_0=x'(0)$ are the initial conditions.
        \end{itemize}
        \item A simple example is downwards motion due to gravity. Then
        \begin{equation*}
            x(t) = \frac{1}{2}
            \begin{pmatrix}
                0\\
                0\\
                -1\\
            \end{pmatrix}
            t^2+v_0t+x_0
        \end{equation*}
        \begin{itemize}
            \item The trajectory in general is a parabola.
        \end{itemize}
        \item Another example: The mathematical pendulum.
        \begin{itemize}
            \item The radial directions balance ($mg\cos\theta$).
            \item The tangential directions do not ($mg\sin\theta$). Thus, our ODE is
            \begin{equation*}
                l\dv[2]{\theta}{t} = g\sin\theta
            \end{equation*}
        \end{itemize}
        \item One last set of examples from ecology:
        \begin{itemize}
            \item Imagine an petri dish of infinite nutrition. The population growth of the bacteria will obey the exponential growth law
            \begin{equation*}
                \dv{y}{t} = ky
            \end{equation*}
            \item Suppose we have a system capacity $M$. Then we obey the logistic growth law
            \begin{equation*}
                \dv{y}{t} = k(M-y)
            \end{equation*}
            \item Lotka-Volterra prey-predator model: Wolf population ($W$) and rabbit population ($R$). We have
            \begin{align*}
                R' &= k_1R-aWR\\
                W' &= -k_2W+bWR
            \end{align*}
            \item We can also introduce more species and capacities and et cetera, et cetera.
        \end{itemize}
    \end{itemize}
    \item Conclusion: Dynamical systems are everywhere, especially in physics, chemistry, and ecology.
    \item We can also consider long-term behavior.
    \begin{itemize}
        \item We can have chaos, but chaos can be reasoned with using oscillation, systems that converge to oscillation, etc. We will mostly be focusing on the regular aspect of the long-term behavior.
    \end{itemize}
\end{itemize}



\section{Origin of ODEs: Boundary Value Problems}
\begin{itemize}
    \item \marginnote{9/30:}Textbook PDFs will be posted today.
    \item Note: Equations of order $n$ generally require $n$ parameters to solve.
    \item Today, we will consider boundary value problems, which are separate from dynamical systems but not entirely unrelated.
    \item \textbf{Boundary Value Problem}: A problem in which we are solving for a $y$ that has fixed values at the boundaries $x=a,b$. \emph{Also known as} \textbf{BVP}.
    \item The \textbf{Brachistochrone problem} is an example of a BVP.
    \item \textbf{Brachistochrone problem}: Suppose you have a frictionless track from $(0,0)$ to $(a,y_0)$ and release a particle from $(0,0)$. Which path allows the particle to get to $(a,y_0)$ in the shortest amount of time? \emph{Etymology} br\'{a}khistos "shortest" + khr\'{o}nos "time."
    \begin{figure}[h!]
        \centering
        \begin{tikzpicture}[
            every node/.style={black}
        ]
            \footnotesize
            \draw (-0.5,0) -- (5,0) node[right]{$x$};
            \draw (0,0.5) node[above]{$y$} -- (0,-3);
    
            \draw [rex,thick] plot[domain=0:pi] ({4/pi*(\x-sin(\x r))},{-(1-cos(\x r))});
            \node at (1,-1) {$\ell$};
            \fill circle (2pt) node[above left]{$(0,0)$};
            \fill (4,-2) circle (2pt) node[below right]{$(a,y_0)$};
            \fill (2,-1.674) circle (2pt) node[below left,xshift=-3pt]{$(x,y(x))$};
            \draw [semithick,-latex] (2,-1.674) -- ++(1,-0.38) node[below]{$v$};
    
            \def\s{0.2}
            \draw
                ({2-\s},{-1.674-0.9*\s}) rectangle ({2+\s},{-1.674+0.9*\s})
                (2,-1.494) -- (2,-1) -- (6,-1)
                (6,-2.35) rectangle (9,0.35)
            ;
            \draw [rex,very thick] plot[domain=2.214:2.402] ({30/pi*(\x-sin(\x r))-7.5},{-7.5*(1-cos(\x r))+11.555});
            \draw [grx,ultra thick] plot[domain=2.25:2.36] ({30/pi*(\x-sin(\x r))-7.5},{-7.5*(1-cos(\x r))+11.555});
            \node [label={above:$\dd{\ell}$}] at (7.5,-1) {};
            \coordinate (L) at ({30/pi*(2.25-sin(2.25 r))-7.5},{-7.5*(1-cos(2.25 r))+11.555});
            \coordinate (R) at ({30/pi*(2.36-sin(2.36 r))-7.5},{-7.5*(1-cos(2.36 r))+11.555});
            \draw [grx,densely dashed] (L) -- node[left]{$\dd{y}$} (L |- R) -- node[below]{$\dd{x}$} (R);
        \end{tikzpicture}
        \caption{Brachistochrone problem.}
        \label{fig:brachistochroneSetup}
    \end{figure}
    \begin{itemize}
        \item Throughout this derivation, we will make several assumptions. We will do our best to note these assumptions as we go in footnotes. Note that while all of these assumptions are justified in the case of solving this problem, they may not be justified in every related variational problem. Let's begin.
        \item Since the track is frictionless, the mechanical energy should be conserved.
        \item At a given point along the curve, the particle has a velocity $v$ and is vertical distance $y$ from where it started. We know from physics that
        \begin{align*}
            \frac{1}{2}mv^2 &= mgy\\
            v &= \sqrt{2gy}
        \end{align*}
        \item Since $v=\dv*{\ell}{t}$, the time $\dd{t}$ it takes for the particle to traverse an infinitesimal section of track of arc length $\dd\ell$ is $\dd{t}=\dd\ell/v$.
        \item The track should be given by $y=y(x)$\footnote{There are paths that connect $(0,0)$ and $(a,y_0)$ that are not functions of $x$. We are taking those out of consideration.}.
        \item Let $\ell$ denote the arc length of the whole track. Then
        \begin{equation*}
            \dd\ell = \sqrt{1+(y'(x))^2}\dd{x}
        \end{equation*}
        \item Thus, the total time for the particle to traverse the curve is
        \begin{equation*}
            t(y) = \int_0^t\dd{\tau}
            = \int_0^a\frac{\dd\ell}{v}
            = \int_0^a\frac{\sqrt{1+(y'(x))^2}\dd{x}}{\sqrt{2gy(x)}}
        \end{equation*}
        \item We also have $y(0)=0$ and $y(a)=y_0$.
        \item We want to find $y$ such that the above integral is minimized. Thus, we define the following \textbf{functional}, which is used to solve general fixed-endpoint variational problems (the Brachistochrone problem is a problem of this type).
        \item Let $J[y]=\int_a^bF(x,y(x),y'(x))\dd{x}$.
        \item The space of functions we're considering is $C^1$ (the set of all continuously differentiable functions)\footnote{This also eliminates some possible paths from consideration.}.
        \item Take a function $h$, vanishing at $a,b$.
        \item Let $f(t)=J[y+th]$. Then
        \begin{equation*}
            f(t) = \int_a^bF(x,\underbrace{y(x)+th(x)}_{z(x,t)},\underbrace{y'(x)+th'(x)}_{w(x,t)})\dd{x}
        \end{equation*}
        \item We know that\footnote{We must assume sufficient regularity of $F$ here. In particular, we must assume that the derivative of the integral of $F$ is equal to the integral of the derivative of $F$.}
        \begin{align*}
            \dv{t}\int_a^bF\dd{x} &= \int_a^b\dv{F}{t}\dd{x}\\
            &= \int_a^b\left( \pdv{F}{x}\dv{x}{t}+\pdv{F}{z}\dv{z}{t}+\pdv{F}{w}\dv{w}{t} \right)\dd{x}\\
            &= \int_a^b\left( \pdv{F}{x}\cdot 0+\pdv{F}{z}\cdot h(x)+\pdv{F}{w}\cdot h'(x) \right)\dd{x}\\
            &= \int_a^b\left( \pdv{F}{z}\cdot h(x)+\pdv{F}{w}\cdot h'(x) \right)\dd{x}
            % \\
            % &= \int_a^b\left( {\pdv{F}{z}}(x,y(x)+th(x),y'(x)+th'(x))h(x)+{\pdv{F}{w}}(x,y(x)+th(x),y'(x)+th'(x))h'(x) \right)\dd{x}\\
            % &= \int_a^b{\pdv{F}{z}}(x,y(x)+th(x),y'(x)+th'(x))h(x)\dd{x}-\dv{x}\left[ {\pdv{F}{w}}(x,y(x)+th(x),y'(x)+th'(x)) \right]h(x)\dd{x}
        \end{align*}
        \begin{itemize}
            \item The last term in the above equation may be integrated by parts as follows. Note that we make use of the hypothesis $h(a)=h(b)=0$ in eliminating the $[uv]_a^b$ term.
            \begin{align*}
                \int_a^b\pdv{F}{w}h'(x)\dd{x} &= \left[ \pdv{F}{w}h(x) \right]_{x=a}^b-\int_a^bh(x)\dv{x}(\pdv{F}{w})\dd{x}\\
                &= \left[ \eval{\pdv{F}{w}}_b\cdot 0-\eval{\pdv{F}{w}}_a\cdot 0 \right]-\int_a^b\dv{x}(\pdv{F}{w})h(x)\dd{x}\\
                &= -\int_a^b\dv{x}(\pdv{F}{w})h(x)\dd{x}
            \end{align*}
            \item Substituting back into the original equation, we obtain
            \begin{align*}
                \dv{t}\int_a^bF\dd{x} &= \int_a^b\left[ \pdv{F}{z}\cdot h(x)-\dv{x}(\pdv{F}{w})h(x) \right]\dd{x}\\
                &= \int_a^b\left[ \pdv{F}{z}-\dv{x}(\pdv{F}{w}) \right]h(x)\dd{x}
            \end{align*}
            \item Therefore,
            \begin{equation*}
                f'(t) = \dv{t}\int_a^bF\dd{x}
                = \int_a^b\left\{ \pdv{F}{z}(x,y(x)+th(x),y'(x)+th'(x))-\dv{x}\left[ \pdv{F}{w}(x,y(x)+th(x),y'(x)+th'(x)) \right] \right\}h(x)\dd{x}
            \end{equation*}
        \end{itemize}
        \item Thus,
        \begin{equation*}
            f'(0) = \int_a^b\left\{ {\pdv{F}{z}}(x,y(x),y'(x))-\dv{x}\left[ {\pdv{F}{w}}(x,y(x),y'(x)) \right] \right\}h(x)\dd{x}
            = 0
        \end{equation*}
        for all $h$.
        \begin{itemize}
            \item Now suppose $y$ is the solution. Then $y$ minimizes $J[y]$. But if this is true, then any variation $th$ will cause $J[y+th]>J[y]$. It follows that for every $h$, $f(t)$ has a minium at $t=0$. But if $f$ has a minimum at 0 for all $h$, then $f'(0)=0$ for all $h$.
        \end{itemize}
        \item Lemma: Let $\phi$ be continuous on $(a,b)$. If for every $h\in C^1([a,b])$ vanishing on $a,b$ we have that
        \begin{equation*}
            \int_a^b\phi(x)h(x)\dd{x} = 0
        \end{equation*}
        then $\phi(x)=0$.
        \begin{proof}
            Suppose for the sake of contradiction that (WLOG) $\phi(x_0)>0$. Then within some neighborhood $N_\delta(x)$ of $x_0$, $\phi(x)>0$ for all $x\in N_\delta(x)$. Now choose $h$ to be a bump function on that interval. Then $\int_a^b\phi(x)h(x)\dd{x}>0$, a contradiction.
        \end{proof}
        \item It follows that
        \begin{equation*}
            {\pdv{F}{z}}(x,y(x),y'(x))-\dv{x}\left[ {\pdv{F}{w}}(x,y(x),y'(x)) \right] = 0
        \end{equation*}
        \begin{itemize}
            \item This is a second-order differential equation, specifically the \textbf{Euler-Lagrange equation}.
            \item It is a necessary condition for $y$ to be an extrema.
            \item Euler-Lagrange equations are not easy to solve in general. However, we're lucky here.
        \end{itemize}
        \item In our example,
        \begin{equation*}
            F(x,z,w) = \sqrt{\frac{1+w^2}{2gz}}
        \end{equation*}
        \begin{itemize}
            \item What's nice here is that $F(x,z,w)=F(z,w)$, i.e., there is no dependence on $x$. This is crucial.
        \end{itemize}
        \item With this observation in mind, notice that
        \begin{align*}
            \dv{F}{x} &= \pdv{F}{z}\dv{z}{x}+\pdv{F}{w}\dv{w}{x}\\
            &= \pdv{F}{z}\dv{y}{x}+\pdv{F}{w}\dv{y'}{x}\\
            &= \pdv{F}{z}\dv{y}{x}+\pdv{F}{w}\dv[2]{y}{x}
        \end{align*}
        \item We now rearrange the E-L equation and multiply through by $\dv*{y}{x}$.
        \begin{align*}
            \pdv{F}{z}-\dv{x}(\pdv{F}{w}) &= 0\\
            \dv{x}(\pdv{F}{w})\dv{y}{x} &= \pdv{F}{z}\dv{y}{x}
        \end{align*}
        \item Subtracting the last two results yields
        \begin{align*}
            \dv{F}{x}-\dv{x}(\dv{F}{w})\dv{y}{x} &= \pdv{F}{w}\dv[2]{y}{x}\\
            \dv{F}{x} &= \dv{x}(\dv{F}{w})\dv{y}{x}+\pdv{F}{w}\dv[2]{y}{x}\\
            &= \dv{x}(\dv{F}{w}\dv{y}{x})\\
            \dv{x}(F-\dv{F}{w}\dv{y}{x}) &= 0\\
            F-\dv{F}{w}\dv{y}{x} &= A
        \end{align*}
        where $A\in\R$ depends on the initial conditions.
        \item From the definition of $F$, we can calculate
        \begin{equation*}
            \pdv{F}{w} = \frac{w}{\sqrt{1+w^2}}\cdot\frac{1}{\sqrt{2gz}}
            = \frac{y'}{\sqrt{1+(y')^2}}\cdot\frac{1}{\sqrt{2gy}}
        \end{equation*}
        \item It follows that our solution function $y$ satisfies the separable differential equation
        \begin{align*}
            \sqrt{\frac{1+(y')^2}{2gy}}-\frac{y'}{\sqrt{1+(y')^2}}\cdot\frac{1}{\sqrt{2gy}}\cdot y' &= A\\
            \frac{1+(y')^2}{\sqrt{1+(y')^2}\sqrt{2gy}}-\frac{(y')^2}{\sqrt{1+(y')^2}\sqrt{2gy}} &= A\\
            \frac{1}{\sqrt{2gy(1+(y')^2)}} &= A\\
            (y')^2 &= \frac{1/2A^2g-y}{y}
        \end{align*}
        \item The solution, as we can determine using methods from Calculus I-II, is the \textbf{cycloid}
        \begin{equation*}
            \begin{cases}
                x = a(\theta-\sin\theta)\\
                y = a(1-\cos\theta)
            \end{cases}
        \end{equation*}
        where the specific parameters come from the boundary values.
    \end{itemize}
    \item \textbf{Functional}: A map from a function space to a set of numbers.
    \item \textbf{Sturm-Liouville problems}: Boundary value problems concerning the integral
    \begin{equation*}
        \int_a^b\left[ p(x)(y'(x))^2+q(x)(y(x))^2 \right]\dd{x}
    \end{equation*}
    \begin{itemize}
        \item The most basic BVP is a vibrating string. In finding the eigenmode of the vibration, you need to solve the above differential equation.
        \item Very important in physics.
        \item If time permits at the end of the course, Shao will return to the following topic in detail.
    \end{itemize}
    \item Next several weeks: \emph{Solvable} differential equations.
\end{itemize}



\section{Chapter 1: Introduction}
\emph{From \textcite{bib:Teschl}.}
\subsection*{Section 1.1: Newton's Equations}
\begin{itemize}
    \item \marginnote{11/11:}Before we begin defining abstract terms, let's look at an example in which many of these terms arise.
    \item Investigation: Describing the motion of a particle using classical mechanics.
    \begin{itemize}
        \item The location, velocity, and acceleration of a particle are typically given by the related functions\footnote{Newton's notation for derivatives uses a number of dots above the dependent variable to indicate the order of the derivative to which we are referring. For example, $\dot{x}$ denotes the first derivative of $x$ with respect to it's independent variable, and $\ddot{x}$ denotes the second derivative of $x$ with respect to it's independent variable.}
        \begin{align*}
            x:\R\to\R^3&&
            v=\dot{x}:\R\to\R^3&&
            a=\dot{v}:\R\to\R^3
        \end{align*}
        \item The particle does not move randomly, though; its motion is governed by an external force field $F:\R^3\to\R^3$ which exerts a vector force $F(x)$ on the particle when it is at $x\in\R^3$.
        \item Additionally, Newton's second law of motion asserts that at every $x\in\R^3$, the force acting on the particle must equal the acceleration of the particle times its mass, that is,
        \begin{equation*}
            m\ddot{x}(t) = F(x(t))
        \end{equation*}
        for all $t\in\R$.
        \item Given a force field $F$, physicists often seek to determine how bodies evolve under $F$ over time. Mathematically, they seek functions $x(t)$ that satisfy $m\ddot{x}(t)=F(x(t))$ for a given $F$.
        \item Consider the example of a stone falling toward the Earth under gravity from class.
        \begin{itemize}
            \item In the vicinity of the surface of Earth, the gravitational force is approximately constant and given by
            \begin{equation*}
                F(x) = -mg
                \begin{pmatrix}
                    0\\
                    0\\
                    1\\
                \end{pmatrix}
            \end{equation*}
            where $g$ is the positive \textbf{gravitational constant} and the $+x_3$ direction is taken to be normal to the Earth's surface.
            \item Hence, the system of differential equations reads
            \begin{align*}
                m\ddot{x}_1 &= 0&
                m\ddot{x}_2 &= 0&
                m\ddot{x}_3 &= -mg
            \end{align*}
            \item The first equation can be integrated with respect to $t$ twice, yielding $x_1(t)=C_2+C_1t$. Computing $x_1(0)$ and $\dot{x}_1(0)$ shows that $C_2=x_1(0)$ and $C_1=v_1(0)$. An analogous result holds for the second equation. For the third equation, we get $x_3(t)=C_2+C_1t-\frac{1}{2}mgt^2$ where $C_2=x_3(0)$ and $C_1=v_1(0)$, again. Thus, the full solution reads
            \begin{equation*}
                x(t) = x(0)+v(0)t-\frac{g}{2}
                \begin{pmatrix}
                    0\\
                    0\\
                    1\\
                \end{pmatrix}
                t^2
            \end{equation*}
        \end{itemize}
    \end{itemize}
    \item \textbf{Differential equation}: A relation between a function $x(t)$ and its derivatives.
    \begin{itemize}
        \item The equation $m\ddot{x}(t)=F(x(t))$, above, is an example of a differential equation.
    \end{itemize}
    \item \textbf{Second-order} (differential equation): A differential equation in which the highest derivative is of second degree.
    \begin{itemize}
        \item The equation $m\ddot{x}(t)=F(x(t))$, above, is an example of a second-order differential equation.
    \end{itemize}
    \item \textbf{$\bm{n}^\textbf{th}$-order} (differential equation): A differential equation in which the highest derivative is of degree $n$.
    \item \textbf{System} (of differential equations): A finite set of differential equations.
    \begin{itemize}
        \item Systems of differential equations vary in how related they are, that is, they may or may not share variables.
        \item Technically, $m\ddot{x}(t)=F(x(t))$ is a system of differential equations since $x=(x_1,x_2,x_3)$ gives rise to three independent differential equations, one for each Cartesian dimension, as follows.
        \begin{align*}
            m\ddot{x}_1 &= F(x_1(t))&
            m\ddot{x}_2 &= F(x_2(t))&
            m\ddot{x}_3 &= F(x_3(t))
        \end{align*}
    \end{itemize}
    \item \textbf{Dependent} (variable): A variable whose value depends on that of another.
    \begin{itemize}
        \item In our example, $x$, $v$, and $a$ are all dependent variables.
    \end{itemize}
    \item \textbf{Independent} (variable): A variable whose value does not depend on that of another.
    \begin{itemize}
        \item In our example, $t$ is the independent variable.
    \end{itemize}
    \item \textbf{First-order} (system): A system of differential equations in which the differential equation of highest order is first order.
    \begin{itemize}
        \item One possible rewrite of the system $m\ddot{x}(t)=F(x(t))$ works by increasing the number of dependent variables from $x\in\R^3$ to $(x,v)\in\R^6$. Indeed, we can rewrite the second-order differential equation $m\ddot{x}(t)=F(x(t))$ as the following first-order system.
        \begin{align*}
            \dot{x}(t) &= v(t)\\
            \dot{v}(t) &= \frac{1}{m}F(x(t))
        \end{align*}
        \item We will find that the above form is often better suited to theoretical investigations.
    \end{itemize}
    \item \textbf{$\bm{n}^\textbf{th}$-order} (system): A system of differential equations in which the differential equation of highest order is $n^\text{th}$ order.
    \item One conclusion of our investigation of gravity's effect on a particle is that the entire fate (past and future) of our particle's position, velocity, and acceleration (under simple gravity) is uniquely determined by its initial location $x(0)$ and velocity $v(0)$.
    \begin{itemize}
        \item While we could use simple integration to solve this system, we cannot always do this (not even under Newtonian universal gravitation).
    \end{itemize}
\end{itemize}


\subsection*{Section 1.2: Classification of Differential Equations}
\begin{itemize}
    \item \marginnote{11/11:}$\bm{C^k(U,V)}$: The set of functions $f:U\to V$ having continuous derivatives up to order $k$, where $U\subseteq\R^m$, $V\subseteq\R^n$, and $k\in\N_0$.
    \item $\bm{C(U,V)}$: The set of continuous functions $f:U\to V$. \emph{Given by}
    \begin{equation*}
        C(U,V) = C^0(U,V)
    \end{equation*}
    \item $\bm{C^\infty(U,V)}$: The set of smooth functions $f:U\to V$. \emph{Given by}
    \begin{equation*}
        C^\infty(U,V) = \bigcap_{k\in\N}C^k(U,V)
    \end{equation*}
    \item $\bm{C^k(U)}$: The set of real functions $f:U\to\R$ having continuous derivatives up to order $k$. \emph{Given by}
    \begin{equation*}
        C^k(U) = C^k(U,\R)
    \end{equation*}
    \item \textbf{Ordinary differential equation}: An equation of the form
    \begin{equation*}
        F(t,x,x^{(1)},\dots,x^{(k)}) = 0
    \end{equation*}
    where $F\in C(U)$ ($U\subseteq\R^{k+2}$ open) relates the unknown function $x\in C^k(J)$ ($J\subseteq\R$), its independent variable $t$, and its first $k$ derivatives;
    \begin{equation*}
        x^{(j)} := \dv[j]{x}{t}
    \end{equation*}
    for $j\in\N_0$. \emph{Also known as} \textbf{ODE}.
    \item \textbf{Order} (of an ODE): The highest derivative appearing in the argument of $F$.
    \item \textbf{Solution} (of an ODE): A function $\phi\in C^k(I)$ ($I\subseteq J$ an interval) satisfying the equation
    \begin{equation*}
        F(t,\phi(t),\phi^{(1)}(t),\dots,\phi^{(k)}(t)) = 0
    \end{equation*}
    for all $t\in I$.
    \item Very little can be said about completely general ODEs.
    \item Thus, we begin our investigation with the subclass of ODEs that can solved for their highest order derivative, that is, with ODEs of the form
    \begin{equation*}
        x^{(k)} = f(t,x,x^{(1)},\dots,x^{(k-1)})
    \end{equation*}
    \begin{itemize}
        \item Relation between these ODEs and general ODEs: These ODEs are the ones for which $F$ has nonzero partial derivative with respect to $y_k$. Indeed, if $F$ satisfies this condition locally near $(x,y_k)\in U$, then the implicit function theorem permits the above rearrangement.
    \end{itemize}
    \item \textbf{System} (of ODEs): A finite set of ODEs. \emph{Given by}
    \begin{align*}
        x_1^{(k)} &= f_1(t,x,x^{(1)},\dots,x^{(k-1)})\\
        &\hspace{0.5em}\vdots\\
        x_n^{(k)} &= f_n(t,x,x^{(1)},\dots,x^{(k-1)})
    \end{align*}
    \begin{itemize}
        \item Note that the use of an unsubscripted $x^{(j)}$ in the argument of each $f_i$ reflects the fact that every $f_i$ is a function of \emph{all} of the components of of $x$ and their derivatives (not just $x_i$ and its derivatives). Symbolically, each $f_i$ is a function of $x_l^{(j)}$ ($l=1,\dots,n$ and $j=0,\dots,k-1$), and
        \begin{equation*}
            f_i:\R\times\underbrace{\R^n\times\cdots\times\R^n}_{k\text{ times}}\to\R
        \end{equation*}
    \end{itemize}
    \item \textbf{Linear} (system): A system of $n$ ordinary differential equations for which each $x_i^{(k)}$ is of the form
    \begin{equation*}
        x_i^{(k)} = g_i(t)+\sum_{l=1}^n\sum_{j=0}^{k-1}f_{i,j,l}(t)x_l^{(j)}
    \end{equation*}
    \begin{itemize}
        \item The summations are over the $n$ components of $x$, and each of their $k$ derivatives up from the function itself ($l=0$) to $l=k-1$. In other words, if a (derivative of) a component of $x$ appears in a linear system, the only modification to it from itself should be a functional coefficient in the independent variable.
    \end{itemize}
    \item \textbf{Homogeneous} (linear system): A linear system for which $g_i(t)=0$.
    \item \textbf{Inhomogeneous} (linear system): A linear system for which $g_i(t)=0$.
    \item \textcite{bib:Teschl} goes over the conversion of a system to a first-order system, as covered in class.
    \begin{itemize}
        \item Also noted: We can include $t$ as a dependent variables by taking $z=(t,y)$ and making $\dot{z}_1=1$, $\dot{z}_i=z_{i+1}$ ($i=2,\dots,k$), and $\dot{z}_{k+1}=f(z)$.
    \end{itemize}
    \item \textbf{Autonomous} (system): A system in which $f$ does not depend on $t$.
    \item We will often limit our studies to autonomous first-order ODEs since, as per the past two results, these encapsulate all higher order, potentially non-autonomous systems as well.
    \item \textbf{Partial differential equation}: A differential equation for which $t\in\R^m$. \emph{Also known as} \textbf{PDE}.
    \begin{itemize}
        \item Name justification: $t\in\R^m$ necessitates the use of partial derivatives.
    \end{itemize}
    \item Complex values will not be considered until later.
\end{itemize}




\end{document}