\documentclass[../notes.tex]{subfiles}

\pagestyle{main}
\renewcommand{\chaptermark}[1]{\markboth{\chaptername\ \thechapter\ (#1)}{}}
\setcounter{chapter}{8}

\begin{document}




\chapter{Periodicity}
\section{Periodic Solutions of Planar Systems}
\begin{itemize}
    \item \marginnote{11/28:}Last lectures: Special solutions to planar systems. Usually encountered in applications of ODEs (e.g., the homework). If we encounter ODEs in our physical sciences lives, we may need to remember this.
    \item There will be a Monday office hours that coincides with the regular lecture time.
    \item Special (periodic) solutions of planar systems.
    \item For a planar autonomous system
    \begin{equation*}
        \begin{pmatrix}
            x\\
            y\\
        \end{pmatrix}'
        =
        \begin{pmatrix}
            f(x,y)\\
            g(x,y)\\
        \end{pmatrix}
    \end{equation*}
    a periodic solution is equivalent to a closed orbit.
    \item So geometrically, we'll be studying closed orbits. Analytically, we'll be studying periodic systems.
    \item Simple examples: Harmonic oscillator
    \begin{equation*}
        \begin{pmatrix}
            x\\
            y\\
        \end{pmatrix}'
        =
        \begin{pmatrix}
            y\\
            -x\\
        \end{pmatrix}
    \end{equation*}
    \item Less trivial example: The pendulum
    \begin{equation*}
        \begin{pmatrix}
            \theta\\
            \omega\\
        \end{pmatrix}'
        =
        \begin{pmatrix}
            \omega\\
            -\sin\theta\\
        \end{pmatrix}
    \end{equation*}
    \item We can easily find Lyapunov functions for these two systems; both functions are the energy function.
    \item Different orbital graphs: The first one is concentric circles; the second one is only sometimes periodic.
    \emph{picture}
    \item In general, these periodic cycles are dense in the plane.
    \item However, we can also, at the other extreme, have isolated periodic solutions, referred to as \textbf{limit cycles}.
    \item Simplest example:
    \begin{equation*}
        \begin{pmatrix}
            x\\
            y\\
        \end{pmatrix}'
        =
        \begin{pmatrix}
            -y-[1-(x^2+y^2)]x\\
            x-[1-(x^2+y^2)]y\\
        \end{pmatrix}
    \end{equation*}
    \begin{itemize}
        \item Hard to see the behavior in Cartesian coordinates; much easier in polar. If we use $r=\sqrt{x^2+y^2}$ and $\theta=\arctan(y/x)$. We will see equations of this type in our homework.
        \item Differentiating $r=\sqrt{x^2+y^2}$ implicitly with respect to time, we get
        \begin{align*}
            \dv{r}{t} &= \frac{xx'}{\sqrt{x^2+y^2}}+\frac{yy'}{\sqrt{x^2+y^2}}\\
            &= -\frac{xy}{\sqrt{x^2+y^2}}+\frac{1-r^2}{r}x^2+\frac{xy}{\sqrt{x^2+y^2}}+\frac{1-r^2}{r}y^2\\
            &= r(1-r^2)\cos^2\theta+r(1-r^2)\sin^2\theta\\
            &= r(1-r^2)
        \end{align*}
        \item Differentiating $\theta=\arctan(y/x)$ implicitly with respect to time, we get
        \begin{align*}
            \dv{\theta}{t} &= \frac{-\frac{y}{x^2}x'}{1+\left( \frac{y}{x} \right)^2}+\frac{\frac{1}{x}y'}{1+\left( \frac{y}{x} \right)^2}\\
            &= \frac{-yx'}{x^2+y^2}+\frac{xy'}{x^2+y^2}\\
            &= 1
        \end{align*}
        \item Thus, we can transform the original equation to
        \begin{equation*}
            \begin{pmatrix}
                r\\
                \theta\\
            \end{pmatrix}'
            =
            \begin{pmatrix}
                r(1-r^2)\\
                1\\
            \end{pmatrix}
        \end{equation*}
        for $r>0$ and $\theta\in\R$.
        \item This ODE can be explicitly solved, but since we are interested in qualitative behavior, we will not do that.
        \item The unit circle partitions the $xy$-plane into two parts (inside and outside).
        \emph{picture}
        \item Let's start on the unit circle. Then we just spiral around on it with constant velocity ($r'=0$ and $\theta'=1$).
        \item Let's now start inside. Since $\theta(t)=t+\theta(0)$, and $r'$ is positive, we get a spiral that approaches the unit circle.
        \item If we start outside, we get a spiral that starts outside and spirals toward the unit circle.
        \item Thus, in this case, the unit circle is the unique limit cycle of the system.
    \end{itemize}
    \item Shao suggests we search for iodine clock videos on YouTube to help with the homework. The iodine clock is described by the limit cycles.
    \item Historical remark: David Hilbert posed 23 questions at the beginning of the 20th century. The 16th one asked about planar polynomial systems. For these, is it possible to estimate the number of limit cycles. Even for the case of quadratic polynomials, the question is still open! For quadratics, we know that there can be 1, 2, 3, or 4 cycles, but we have no idea whether or not there is an upper bound. This is a central open problem in the study of ODEs.
    \item Basic theorem in this area is as follows.
    \item Theorem (Poincar\'{e}-Bendixson Theorem): Let $\Omega\in\R^2$ be open, $f(x)$ a vector field on $\Omega$. Fix $x\in\Omega$. Define
    \begin{equation*}
        \omega(x) := \{z\in\Omega\mid\text{there is a sequence }t_n\to +\infty\text{ such that }\phi_{t_n}(x)\to z\}
    \end{equation*}
    and
    \begin{equation*}
        \alpha(x) := \{z\in\Omega\mid\text{there is a sequence }t_n\to -\infty\text{ such that }\phi_{t_n}(x)\to z\}
    \end{equation*}
    That is, if you reverse the direction of time, $\alpha(x)$ collects all of the points. Also, let $\omega(x)\subset\Omega$ be compact and nonempty. In particular, there are three mutually exclusive cases for these limit sets.
    \begin{enumerate}
        \item $\omega(x)$ (or $\alpha(x)$\footnote{We just have to reverse the time.}) is a fixed point.
        \item $\omega(x)$ is a limit cycle.
        \item $\omega(x)$ consists of finitely many fixed points, together with curves joining these fixed points.
    \end{enumerate}
    \begin{proof}
        The proof relies largely on algebraic topology, so we will not go into it in detail or even sketch it. The statement will be sufficient for our purposes.
    \end{proof}
    \item Theorem (Annulus theorem of Bendixson): Suppose $C_1,C_2$ are closed simple planar curves such that geometrically, one contains the other. We call the annular region (between the two curves) $A$. Suppose $f(x)$ is a planar vector field which points inward at every point of $\partial A$ (the boundary of $A$). Then the annular region $A$ is an invariant region of the plane. In particular, if $A$ does not contain any fixed points, then it must contain a limit cycle. As before, curves within and without spiral towards it.
    \emph{picture}
    \item Can produce beautiful diagrams: Zhifen Zhang's example --- \textcite{bib:Zhang} --- is the 4 limit cycle one. After her research, mathematicians found a family with four limit cycles.
    \item System from the homework: Consider the system
    \begin{equation*}
        \begin{pmatrix}
            x\\
            y\\
        \end{pmatrix}'
        =
        \begin{pmatrix}
            a-x-\frac{4xy}{1+x^2}\\
            b(x-\frac{xy}{1+x^2})\\
        \end{pmatrix}
    \end{equation*}
    \emph{picture}
    \begin{itemize}
        \item We take $a,b>0$.
        \item Every vector points in toward $a$, which points straight upward.
        \item On the boundary,
        \begin{equation*}
            \begin{pmatrix}
                a-x-\frac{4xy}{1+x^2}\\
                b(x-\frac{xy}{1+x^2})\\
            \end{pmatrix}
            \cdot
            \begin{pmatrix}
                0\\
                1\\
            \end{pmatrix}
            > 0
        \end{equation*}
        so we have a strict Lyapunov function.
        \item Thus, any orbit in the first quadrant can never escape, reflecting our expectation that the concentration can never be negative.
        \item Spoiler: Looks like a rectangular region.
        \item We are also asked to find the fixed point and investigate its stability.
    \end{itemize}
    \item First step: Find fixed points.
    \item Second step: Lyapunov functions.
    \item Third step: Divide the vector field into positive and negative regions. Requires some improvization.
    \item Fourth step: Check for an annular region.
    \item Note: Note of these arguments can be generalized to higher dimensional systems. The regularity of the Poincar\'{e}-Bendixson system disappears as we go to higher dimensions.
    \item Lorenz system: Oversimplified 3D quadratic system that serves as a simplification model for weather systems.
    \begin{itemize}
        \item Lorenz was an astronomer.
        \item He discovered that even if the systems are very close together, the orbits will be separated indefinitely as time evolves on. It's not just about being stable or unstable, but overall global chaotic behavior.
        \item Mathematicians quickly discovered that the Lorenz system has a \textbf{strange attractor}. An attractor for a planar system can only be closed orbits. In the Lorenz system, we have a strange type of butterfly. The dimension of the butterfly is not even an integer. Have to introduce Hausdorff measure to understand length and area in the more general framework of curves or surfaces.
        \item No more detail, but a classical example of a chaotic ODE system worth mentioning. This phenomenon cannot appear for planar systems; even increasing the dimension by 1 can lead to chaos.
        \item No widely accepted definition of mathematical chaos, but generally accepted ones are very irregular global attractors and points that are arbitrarily close and arbitrarily far from each other.
        \item Fractorial sets.
    \end{itemize}
    \item Last lecture (Wednesday): Another example that has a limit cycle.
    \item Friday will be a review.
\end{itemize}



\section{Nonlinear Oscillation}
\begin{itemize}
    \item \marginnote{11/30:}Friday: Review and questions session.
    \item Monday: OH during class time in the class room and normal OH.
    \item Exam time: Wednesday, December 7 from 7:30-9:30 AM. Will happen in this classroom; Shao hopes to finish grading the same day.
    \item Last HW and review outline is due 12/2. 130 total points for the grade. 90/130 gives an A. That's 69\% and above.
    \begin{itemize}
        \item Minus 10, minus 10, for the grading below A range.
    \end{itemize}
    \item Last example that arises naturally.
    \item RLC circuit: Nonlinear oscillation. Occurred in resonance. Nonlinear oscillation in $K$.
    \item The circuit that we're interested in still is an RLC circuit (see Figure \ref{fig:drivenHOoriginb}).
    \item We assume that the resistor satisfies Ohm's law, i.e., $I_R=V_R/R$. This is the linear case. Causes the voltage to decay exponentially fast, where the resistor acts as a kind of damping factor.
    \item However, for some more delicate cases, Ohm's law might fail and we might get a nonlinear replacement $V_R=R(I_R)$. We let $R$ be any suitable function. We still have Kirchoff's law, i.e., that $I_R$, $I_C$, and $I_L$ are all the same and we can refer to them as $I$.
    \item The system we're interested in is
    \begin{equation*}
        \begin{cases}
            LI' &= -V_C-R(I)\\
            CV' &= I
        \end{cases}
    \end{equation*}
    \item Comparing to the linear case, we just want to replace $V_R/R$ in the same system with $R(I)$. After some suitable scaling, we can get the system
    \begin{equation*}
        \begin{cases}
            x' &= y-f(x)\\
            y' &= -x
        \end{cases}
    \end{equation*}
    \item This is a classical nonlinear oscillation model, typically referred to as the \textbf{Li\'{e}nard equation}.
    \item The first case of the Li\'{e}nard equation studied in detail was when
    \begin{equation*}
        f(x) = \mu\left( \frac{x^3}{3}-x \right)
    \end{equation*}
    \begin{itemize}
        \item Discovered by the engineer van der Pol while he was investigating RLC circuits, and hence referred to as the \textbf{van der Pol oscillator}.
    \end{itemize}
    \item Theorem: Suppose $f(x)$ is odd, i.e., $f(x)=-f(-x)$. Also suppose that $f(x)<0$ for $x\in(0,\alpha)$ for some $\alpha>0$ (i.e., $f(x)$ is less than zero for sufficiently small positive values of $x$). Moreover, suppose that $\liminf_{x\to\infty}f(x)>0$ (i.e., $f$ does not diverge). Lastly, suppose that $f(x)$ is increasing for $x>\alpha$. Then the conclusion is that the Li\'{e}nard system has a unique closed orbit. Every other orbit except for the trivial orbit $(0,0)$ will be attracted to this periodic solution as the system evolves ($t\to +\infty$).
    \begin{itemize}
        \item This explains the term "nonlinear oscillation." As long as we are away from the equilibrium, we converge to it??
    \end{itemize}
    \item Wrt the van der Pol oscillator, we sketch the boundary first and then put in the limit cycle. The origin is an unstable fixed point, and any origin starting from the origin will spiral and approximate the limit cycle.
    \begin{itemize}
        \item ?? is guaranteed by the Poincar\'{e}-Bendixson theorem.
    \end{itemize}
    \item The proof does not use any advanced math, but it is complex, so we'll sketch it. The proof is in \textcite{bib:Teschl} if we're interested. It only involves calculus.
    \item End of lecture.
    \item First problem, second section of HW: First integral: Conservative law.
    \item What is the correct first variational equation?
    \item Difference between not Lyapunov stable and completely unstable?
    \begin{itemize}
        \item Something is repelled away vs. everything is repelled away.
    \end{itemize}
    \item The iodine clock is not super hard, but it needs some improvisation. That's what we talked about at the end of last lecture.
    \item Friday will be a review of everything since the second midterm.
\end{itemize}



\section{Question Session}
\begin{itemize}
    \item \marginnote{12/2:}The actual Lecture 9.1 system is
    \begin{equation*}
        \begin{pmatrix}
            x\\
            y\\
        \end{pmatrix}'
        =
        \begin{pmatrix}
            -y-[1-(x^2+y^2)]x\\
            x-[1-(x^2+y^2)]y\\
        \end{pmatrix}
    \end{equation*}
    \item Cannot derive a phase portrait spiral from a potential energy function.
    \begin{itemize}
        \item Relevant to 3c.
        \item Idea is to show that the potential energy well is decreasing along any trajectory.
    \end{itemize}
    \item $r=\sqrt{c_0}$.
    \begin{itemize}
        \item Limit cycle is omega and alpha limit cycle.
    \end{itemize}
    \item Solving for the stable and unstable manifolds.
    \begin{itemize}
        \item Stable set consists of points which are attracted to the equilibrium. Curves are not attracted or repelled.
        \item Stable subset: Points $(z,w)$ such that $(x,y)\to(0,0)$ as $t\to +\infty$. Stable subset: necessitates taking $w=0$ and then $z$ can be anything, so $x$ axis. 
        \item Unstable: As $t\to -\infty$, $w$ can be anything and $y(t) \to 0$. The $+t$ terms will go to zero as $t\to -\infty$, and then we must have $z-w/2=0$. Put it in the form
        \begin{align*}
            x(t) &= (w^2(\e[2t]-\e[t])+\frac{w\e[t]}{2})+(z-\frac{w}{2})\e[-t]\\
            &= ((w\e[t])^2+\frac{w\e[t]}{2})-w^2\e[t]+(z-\frac{w}{2})\e[-t]\\
            &= (y^2+\frac{y}{2})-w^2\e[t]+(z-\frac{w}{2})\e[-t]
        \end{align*}
        \item There is a typo in the original form. There should be $\e[-t]$ for the last rightmost term above. We will converge and diverge along the manifolds.
        \item I have a confusion in the stable/unstable subset definition? Unstable subset isn't the set of all points with orbits that diverge as $t\to +\infty$; it's the set of all points that diverge away from $x_0$.
    \end{itemize}
    \item Solving for the stable and unstable manifolds of a planar ODE given the explicit solution.
    \begin{itemize}
        \item We will treat
        \begin{equation*}
            \begin{pmatrix}
                x\\
                y\\
            \end{pmatrix}'
            =
            \begin{pmatrix}
                -x+y+3y^2\\
                y\\
            \end{pmatrix}
        \end{equation*}
        from Lecture 8.2.
        \item The correct flow is as follows (there was a typo in class).
        \begin{equation*}
            \phi_t
            \begin{pmatrix}
                z\\
                w\\
            \end{pmatrix}
            =
            \begin{pmatrix}
                z\e[-t]+w\sinh(t)+w^2(\e[2t]-\e[-t])\\
                w\e[t]\\
            \end{pmatrix}
        \end{equation*}
        \item The stable manifold is going to be the set of all $x\in\R^2$ such that $\phi_t(x)\to 0$ as $t\to +\infty$. Approach: Find values of $z,w$ such that the solution converges to zero componentwise.
        \begin{itemize}
            \item Since $y(t)=w\e[t]$, we must have $w=0$; otherwise, we will get exponential divergence as $t\to +\infty$.
            \item Thus, $x(t)=z\e[-t]$. This function converges to zero for any value of $z$, so we may let $z$ be arbitrary.
            \item But the set of all points
            \begin{equation*}
                \begin{pmatrix}
                    z\\
                    0\\
                \end{pmatrix}
            \end{equation*}
            is the $x$-axis!
        \end{itemize}
        \item Unstable manifold: We need to find the set of all points $x\in\R^2$ such that $\phi_t(x)\to 0$ as $t\to -\infty$. Approach: Again, go by components.
        \begin{itemize}
            \item $y(t)=w\e[t]$ will converge to 0 as $t\to -\infty$ for all $w$, so this component does not put any restrictions on $w$. Note that it also does not put any restrictions on $z$ since it does not even contain $z$.
            \item Working with the other one, we expand and combine all $\e[at]$ terms for $a>0$ and all $\e[bt]$ terms for all $b<0$.
            \begin{align*}
                x(t) &= z\e[-t]+w\sinh(t)+w^2(\e[2t]-\e[-t])\\
                &= z\e[-t]+w\cdot\frac{\e[t]-\e[-t]}{2}+w^2\e[2t]-w^2\e[-t]\\
                &= z\e[-t]+\frac{w}{2}\e[t]-\frac{w}{2}\e[-t]+w^2\e[2t]-w^2\e[-t]\\
                &= \left[ w^2\e[2t]+\frac{w}{2}\e[t] \right]+\left[ z-\frac{w}{2}-w^2 \right]\e[-t]
            \end{align*}
            \item The left term above will clearly converge to 0 as $t\to -\infty$.
            \item However, the right term will diverge to $\infty$ as $t\to -\infty$ unless $z-w/2-w^2=0$, so we take this to be our condition.
            \item Indeed, this implies that $z=w/2+w^2$ is a constraint on $z$, but $w$ can still take on any value, so our solution is
            \begin{equation*}
                W_u(0) = \left\{ \left( \frac{y}{2}+y^2,y \right) \,\middle|\, y\in\R \right\}
            \end{equation*}
            as desired.
        \end{itemize}
        % \item Shao also clearly labeled unstable vs. stable wrong in class and drew an incorrect picture first.
    \end{itemize}
    \item Number 5:
    \begin{itemize}
        \item What is a vector field in 1d? Vectors pointing in the positive or negative $x$ direction (just a function).
        \item Set of points should be a subset of the real line (an interval).
        \item You can only approach the zero.
    \end{itemize}
    \item Number 3 energy term.
    \begin{itemize}
        \item Multiply both sides by $x'$ to get
        \begin{equation*}
            x'x'' = \frac{1}{2}(x')^2
        \end{equation*}
        \item We have
        \begin{align*}
            0 &= x''+bx'+U'(x)\\
            &= x'x''+b|x'|^2+x'U'(x)\\
            &= \left( \frac{1}{2}(x')^2 \right)'+b|x'|^2+(U(x))'\\
            -b|x'|^2 &= \dv{t}(\frac{1}{2}(x')^2+U(x))
        \end{align*}
    \end{itemize}
    \item Lyapunov stuff. Was a question in HW6.
    \begin{itemize}
        \item ...
        \item Intuitive justification for this Lyapunov function?
        \item Most natural way is to look at when $A$ is diagonalizable.
        \item Get expressions with negative eigenvalues.
        \item We have that the sum is equal to $\dv{t}\langle y,Dy \rangle$. The INP is equal to $2\langle Dy,Dy \rangle$.
        \item So it's a weighted norm.
    \end{itemize}
    \item We'll be allowed to bring the JNF notes to the exam!
\end{itemize}



\section{Office Hours (Shao)}
\begin{itemize}
    \item Question 3(1): How do we derive the energy function?
    \begin{itemize}
        \item We don't actually need to give a final expression for the energy function; just show that it's always decreasing.
    \end{itemize}
    \item Question 3(2): How should we apply the stable manifold theorem and Hartman linearization theorem?
    \begin{itemize}
        \item By the stable manifold theorem, we can determine source, sink, saddle.
        \item By the Hartman linearization theorem, we can further characterize the saddle point by saying that all orbits not on the stable/unstable manifolds (which we don't have to find) approach the fixed point and then diverge away.
        \item Submit a sketch of the local behavior of each one with my answer!!
    \end{itemize}
    \item Question 4(3): What does this even mean?
    \begin{itemize}
        \item Solution is $1/3(x^3+y^3)+xy=a$.
        \item As $a\to 1/3$, the orbits have shape very similar to an ellipse.
        \item We need $a=0$ because we must have the system pass through zero.
        \item This is related to the Lotka-Voterra model from Lecture 2.1.
        \item $F$ is called a first integral.
        \begin{itemize}
            \item To be more general, in an undamped Newtonian system, the energy function is a first integral of the system. Think like quantum mechanics and vibrational energy levels being equivalent to segments of the energy parabola. More generally, though, this perspective applies to all mechanical systems via Hamiltonian mechanics. We don't need to understand Hamiltonian mechanics for this course, though, because we've defined phase spaces independently (a phase space is like the $(\theta,\omega)$ plane for the harmonic oscillator).
            \item We talked about first integrals when we discussed the Kepler problem. The Kepler problem is covered in Section 8.5 of \textcite{bib:Teschl}.
        \end{itemize}
        \item We take
        \begin{align*}
            \frac{x'}{y'} &= \frac{-x-y^2}{x^2+y}\\
            (x^2+y)\dv{x}{t} &= (-x-y^2)\dv{y}{t}\\
            (x^2+y)\dv{x}{t}+(x+y^2)\dv{y}{t} &= 0
        \end{align*}
        Solve this for $F$, which will be a polynomial.
    \end{itemize}
    \item Question 4(4): What does this even mean?
    \begin{itemize}
        \item For the $c=0$ case, the stable set is the part of the curve tangent to the $x$-axis and the unstable set is the part of the curve tangent to the $y$-axis. We get a change from stable to unstable at $(0,0)$ and $(-1.5,-1.5)$.
    \end{itemize}
    \item Enzyme kinetics 1(1): What does "two first integrals" mean?
    \begin{itemize}
        \item First conservation law: Conservation of the substrate in all its forms. Second: Conservation of the enzyme in all its forms.
        \item Sum of the second and third equations equals zero.
        \item Sum of first, third, and fourth is zero.
        \item We have
        \begin{equation*}
            0 = \dv{\cnc{E}}{t}+\dv{\cnc{ES}}{t}
        \end{equation*}
        This is also obvious from their definitions. Thus, $\cnc{E}+\cnc{ES}=\cnc[0]{E}$ is a first integral.
        \item This is not an equation of exact form because of 3 derivatives, but it still implies a conservation law/has a first integral:
        \begin{equation*}
            0 = \dv{\cnc{S}}{t}+\dv{\cnc{ES}}{t}+\dv{\cnc{P}}{t}
        \end{equation*}
        That first integral is $\cnc{S}+\cnc{ES}+\cnc{P}=\cnc[0]{S}$
    \end{itemize}
    \item Iodine Clock: 2(1)?
    \begin{itemize}
        \item Ben knows what's going on here.
        \item There are curves that divide the first quadrant into regions of definite sign.
        \item Definite sign: Neither component changes sign in a certain region
    \end{itemize}
\end{itemize}



\section{Chapter 7: Planar Dynamical Systems}
\emph{From \textcite{bib:Teschl}.}
\subsection*{Section 7.2: Examples from Electrical Engineering}
\begin{itemize}
    \item \marginnote{12/6:}Consider an RLC circuit again, but this time with a resistor of arbitrary characteristic
    \begin{equation*}
        V_R = R(I_R)
    \end{equation*}
    \begin{itemize}
        \item Ohm's law asserts that $R(I_R)=RI_R$, where the resistance $R$ is a constant.
        \item But what about a stranger, more sophisticated element? We must have $R(0)=0$ (since there's no potential difference if there's no current) for any characteristic, but other than that, we're pretty free.
    \end{itemize}
    \item \textbf{Diode}: A circuit element that lets the current pass in only one direction.
    \begin{itemize}
        \item For example, the characteristic of a diode is given by
        \begin{equation*}
            V = \frac{kT}{q}\log(1+\frac{I}{I_L})
        \end{equation*}
        where $I_L$ is the leakage current, $q$ is the charge of an electron, $k$ is the Boltzmann constant, and $T$ is the absolute temperature.
        \item Implications: In the positive direction, very little voltage gives a large current; in the negative direction, you will get almost no current even for fairly large voltages.
    \end{itemize}
    \item As in class, we obtain the system
    \begin{align*}
        L\dot{I}_L &= -V_C-R(I_L)\\
        C\dot{V}_C &= I_L
    \end{align*}
    where $R(0)=0$ and $L,C>0$.
    \item Additional note.
    \begin{itemize}
        \item Kirchoff's laws and the substitutions from Section 3.3 imply
        \begin{align*}
            I_LV_L+I_CV_C+I_RV_R &= 0\\
            LI_L\dot{I}_L+CV_C\dot{V}_C+I_RR(I_R) &= 0\\
            \dv{t}(\frac{L}{2}I_L^2+\frac{C}{2}V_C^2) &= -I_RR(I_R)
        \end{align*}
        \item Conclusion: The energy dissipated in the resistor has to come from the inductor and capacitor.
    \end{itemize}
    \item \textbf{Li\'{e}nard's equation}: The result of scaling the above system. \emph{Given by}
    \begin{align*}
        \dot{x} &= y-f(x)\\
        \dot{y} &= -x
    \end{align*}
    \item The additional note now reads
    \begin{equation*}
        \dv{t}W(x,y) = -xf(x)
    \end{equation*}
    where
    \begin{equation*}
        W(x,y) = \frac{x^2+y^2}{2}
    \end{equation*}
    \begin{itemize}
        \item If $xf(x)>0$ in a neighborhood of $x=0$, then $W$ is a Lyapunov function and hence $(0,0)$ is stable.
    \end{itemize}
    \item Theorem 7.5: Suppose $xf(x)\geq 0$ for all $x\in\R$ and $xf(x)>0$ for $0<|x|<\varepsilon$. Then every trajectory of Li\'{e}nard's equation converges to $(0,0)$.
    \begin{proof}
        Given.
    \end{proof}
    \item Conversely, if $xf(x)<0$ for $0<|x|<\varepsilon$, then $(0,0)$ is unstable (and the distance to the fixed point will actually grow).
    \item \textcite{bib:Teschl} works through proving the main theorem from lecture (Theorem 7.8 below).
    \item Theorem 7.8: Suppose $f$ satisfies requirements (i)-(iii) below.
    \begin{enumerate}[label={(\roman*)}]
        \item $f$ is odd, that is, $f(-x)=-f(x)$.
        \item $f(x)<0$ for $0<x<\alpha$ ($f(\alpha)=0$ without restriction).
        \item $\liminf_{x\to\infty}f(x)>0$ and, in particular, $f(x)>0$ for $x>\beta$ ($f(\beta)=0$ without restriction).
        \item $f(x)$ is monotone increasing for $x>\alpha$ (i.e., $\alpha=\beta$).
    \end{enumerate}
    Then Li\'{e}nard's equation has at least one periodic orbit encircling $(0,0)$.\par
    If in addition (iv) holds, this periodic orbit is unique and every trajectory (except $(0,0)$) converges to this orbit as $t\to\infty$.
    \item The classical application of this theory is to \textbf{van der Pol's equation}.
    \item \textbf{Van der Pol's equation}: The following ODE, which models a triode circuit. \emph{Given by}
    \begin{equation*}
        \ddot{x}-\mu(1-x^2)\dot{x}+x = 0
        ,\quad
        \mu > 0
    \end{equation*}
    \item We can show that van der Pol's equation is equivalent to Li\'{e}nard's equation with
    \begin{equation*}
        f(x) = \mu\left( \frac{x^3}{3}-x \right)
    \end{equation*}
    \item Therefore, by Theorem 7.8, van der Pol's equation has a unique periodic orbit and all trajectories converge to this orbit as $t\to\infty$.
\end{itemize}


\subsection*{Section 7.3: The Poincar\'{e}-Bendixson Theorem}
\begin{itemize}
    \item In all previous examples, the solutions of ODEs have either converged to a fixed point or a periodic orbit.
    \begin{itemize}
        \item This is normal behavior, and in this section we will classify all possible $\omega_\pm$-limit sets (for planar systems).
        \item Note that the difference between $\R^2$ and $\R^n$ ($n\geq 3$) arises from the validity of the \textbf{Jordan Curve Theorem} in $\R^2$ and its being false in higher dimensions.
    \end{itemize}
    \item \textbf{Jordan curve}: A homeomorphic image of the circle $S^1$. \emph{Denoted by} $\bm{J}$.
    \item \textbf{Jordan Curve Theorem}: Every Jordan curve dissects $\R^2$ into two connected regions. In particular, $\R^2\setminus J$ ahs two components.
    \item \textcite{bib:Teschl} builds up to proving the Poincar\'{e}-Bendixson theorem.
    \item Theorem 7.16 (generalized Poincar\'{e}-Bendixson): Let $M$ be an open subset of $\R^2$ and $f\in C^1(M,\R^2)$. Fix $x\in M$, $\sigma\in\{\pm\}$, and suppose $\omega_\sigma(x)\neq\emptyset$ is compact, connected, and contains only finitely many points. Then one of the following cases holds.
    \begin{enumerate}[label={(\roman*)}]
        \item $\omega_\sigma(x)$ is a fixed orbit.
        \item $\omega_\sigma(x)$ is a regular periodic orbit.
        \item $\omega_\sigma(x)$ consists of (finitely many) fixed points $\{x_j\}$ and non-closed orbits $\gamma(y)$ such that $\omega_\pm(y)\in\{x_j\}$.
    \end{enumerate}
    \item \textcite{bib:Teschl} gives an example of the third case.
    \item Lemma 7.17: The interior of every periodic orbit must contain a fixed point.
    \item \textbf{Limit cycle}: A periodic orbit attracting other orbits.
    \item Lemma 7.18: Let $\gamma(y)$ be an isolated regular periodic orbit (such that there are no other periodic orbits within a neighborhood). Then every orbit $\gamma(x)$ starting sufficiently close to $\gamma(y)$ will have either $\omega_-(x)=\gamma(y)$ or $\omega_+(x)=\gamma(y)$.
    \item Example: In general, the system
    \begin{align*}
        \dot{x} &= -y+f(r)x&
        \dot{y} &= x+f(r)y
    \end{align*}
    becomes
    \begin{align*}
        \dot{r} &= rf(r)&
        \dot{\theta} &= 1
    \end{align*}
    for any function $f$.
\end{itemize}



\section{Chapter 8: Higher Dimensional Dynamical Systems}
\emph{From \textcite{bib:Teschl}.}
\subsection*{Section 8.1: Attracting Sets}
\begin{itemize}
    \item Not much of relevance here.
    \item A bit on the Duffing equation from HW7.
    \item \textbf{Topologically transitive} (set): A closed invariant set $\Lambda$ such that for any two open sets $U,V\subset\Lambda$, there is some $t\in\R$ such that $\Phi(t,U)\cap V\neq\emptyset$.
    \item \textbf{Attractor}: An attracting set which is topologically transitive. \emph{Denoted by} $\bm{\Lambda}$.
\end{itemize}


\subsection*{Section 8.2: The Lorenz Equation}
\begin{itemize}
    \item \textbf{Lorenz equation}: One of the most famous dynamical systems which exhibits chaotic behavior. \emph{Given by}
    \begin{align*}
        \dot{x} &= -\sigma(x-y)\\
        \dot{y} &= rx-y-xz\\
        \dot{z} &= xy-bz
    \end{align*}
    where $\sigma,r,b>0$.
    \begin{itemize}
        \item "Lorenz arrived at these equations when modelling a two-dimensional fluid cell between two parallel plates which are at different temperatures. The corresponding situation is described by a complicated system of nonlinear partial differential equations. To simplify the problem, he expanded the unknown functions into Fourier series with respect to the spacial coordinates and set all coefficients except for three equal to zero. The resulting equation for the three time dependent coefficients is [the above]. The variable $x$ is proportional to the intensity of convective motion, $y$ is proportional to the temperature difference between ascending and descending currents, and $z$ is proportional to the distortion from linearity of the vertical temperature profile" \parencite[234]{bib:Teschl}.
    \end{itemize}
    \item \textbf{Strange attractor}: An attractor that has a complicated set structure.
\end{itemize}




\end{document}